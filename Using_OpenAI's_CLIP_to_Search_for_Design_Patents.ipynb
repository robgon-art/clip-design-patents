{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using OpenAI's CLIP to Search for Design Patents",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/clip-design-patents/blob/main/Using_OpenAI's_CLIP_to_Search_for_Design%C2%A0Patents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiE32POvDuoV"
      },
      "source": [
        "# **Using OpenAI's CLIP to Search for Design Patents**\r\n",
        "\r\n",
        "Using natural language to search and find over sixty thousand industrial designs that have entered the public domain since 2002\r\n",
        "\r\n",
        "This Colab is based on https://github.com/openai/CLIP/blob/main/notebooks/Interacting_with_CLIP.ipynb\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh2t4pWYZJd3",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "!gdown --id 1-0PqTuOMhpiNtFepmjGWU79mj3Tckk3w\n",
        "!gdown --id 1-06qsyzgGV0HWnT6JVzgC3SVK2GSOiPT\n",
        "!gdown --id 1--SezGS4Fjnj0t6WFEOBXPSmPQhmaZ_L\n",
        "!gdown --id 1--0ThLCj8rxSFNODbY-RM2qZsv3Sd7UX\n",
        "import numpy as np\n",
        "import torch\n",
        "text_features = torch.tensor(np.load('text_features.npy'))\n",
        "image_features = torch.tensor(np.load('image_features.npy'))\n",
        "import pickle\n",
        "f = open(\"labels.pkl\",'rb')\n",
        "labels = pickle.load(f)\n",
        "f.close()\n",
        "!unzip design_patent_images.zip > /dev/null 2>&1\n",
        "import glob\n",
        "image_files = sorted(glob.glob(\"design_patent_images/*.png\"))\n",
        "!wget https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt -O model.pt\n",
        "model = torch.jit.load(\"model.pt\").cuda().eval()\n",
        "input_resolution = model.input_resolution.item()\n",
        "context_length = model.context_length.item()\n",
        "vocab_size = model.vocab_size.item()\n",
        "!wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz\n",
        "from functools import lru_cache\n",
        "@lru_cache()\n",
        "def bytes_to_unicode():\n",
        "    \"\"\"\n",
        "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
        "    The reversible bpe codes work on unicode strings.\n",
        "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
        "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
        "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
        "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
        "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
        "    \"\"\"\n",
        "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
        "    cs = bs[:]\n",
        "    n = 0\n",
        "    for b in range(2**8):\n",
        "        if b not in bs:\n",
        "            bs.append(b)\n",
        "            cs.append(2**8+n)\n",
        "            n += 1\n",
        "    cs = [chr(n) for n in cs]\n",
        "    return dict(zip(bs, cs))\n",
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs\n",
        "def basic_clean(text):\n",
        "    text = ftfy.fix_text(text)\n",
        "    text = html.unescape(html.unescape(text))\n",
        "    return text.strip()\n",
        "def whitespace_clean(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "class SimpleTokenizer(object):\n",
        "    def __init__(self, bpe_path: str = \"bpe_simple_vocab_16e6.txt.gz\"):\n",
        "        self.byte_encoder = bytes_to_unicode()\n",
        "        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n",
        "        merges = gzip.open(bpe_path).read().decode(\"utf-8\").split('\\n')\n",
        "        merges = merges[1:49152-256-2+1]\n",
        "        merges = [tuple(merge.split()) for merge in merges]\n",
        "        vocab = list(bytes_to_unicode().values())\n",
        "        vocab = vocab + [v+'</w>' for v in vocab]\n",
        "        for merge in merges:\n",
        "            vocab.append(''.join(merge))\n",
        "        vocab.extend(['<|startoftext|>', '<|endoftext|>'])\n",
        "        self.encoder = dict(zip(vocab, range(len(vocab))))\n",
        "        self.decoder = {v: k for k, v in self.encoder.items()}\n",
        "        self.bpe_ranks = dict(zip(merges, range(len(merges))))\n",
        "        self.cache = {'<|startoftext|>': '<|startoftext|>', '<|endoftext|>': '<|endoftext|>'}\n",
        "        self.pat = re.compile(r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\", re.IGNORECASE)\n",
        "    def bpe(self, token):\n",
        "        if token in self.cache:\n",
        "            return self.cache[token]\n",
        "        word = tuple(token[:-1]) + ( token[-1] + '</w>',)\n",
        "        pairs = get_pairs(word)\n",
        "        if not pairs:\n",
        "            return token+'</w>'\n",
        "        while True:\n",
        "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
        "            if bigram not in self.bpe_ranks:\n",
        "                break\n",
        "            first, second = bigram\n",
        "            new_word = []\n",
        "            i = 0\n",
        "            while i < len(word):\n",
        "                try:\n",
        "                    j = word.index(first, i)\n",
        "                    new_word.extend(word[i:j])\n",
        "                    i = j\n",
        "                except:\n",
        "                    new_word.extend(word[i:])\n",
        "                    break\n",
        "\n",
        "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "                    new_word.append(first+second)\n",
        "                    i += 2\n",
        "                else:\n",
        "                    new_word.append(word[i])\n",
        "                    i += 1\n",
        "            new_word = tuple(new_word)\n",
        "            word = new_word\n",
        "            if len(word) == 1:\n",
        "                break\n",
        "            else:\n",
        "                pairs = get_pairs(word)\n",
        "        word = ' '.join(word)\n",
        "        self.cache[token] = word\n",
        "        return word\n",
        "    def encode(self, text):\n",
        "        bpe_tokens = []\n",
        "        text = whitespace_clean(basic_clean(text)).lower()\n",
        "        for token in re.findall(self.pat, text):\n",
        "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
        "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
        "        return bpe_tokens\n",
        "    def decode(self, tokens):\n",
        "        text = ''.join([self.decoder[token] for token in tokens])\n",
        "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=\"replace\").replace('</w>', ' ')\n",
        "        return text\n",
        "!pip install ipyplot\n",
        "!pip install ftfy\n",
        "combined_features = torch.hstack((text_features, image_features))\n",
        "combined_features /= combined_features.norm(dim=-1, keepdim=True)\n",
        "import gzip\n",
        "import regex as re\n",
        "import ftfy\n",
        "from PIL import Image\n",
        "tokenizer = SimpleTokenizer()\n",
        "def get_text_features(sentence):\n",
        "  text_tokens = [tokenizer.encode(\"%s \"%(sentence) + \"<|endoftext|>\")]\n",
        "  text_input = torch.zeros(len(text_tokens), model.context_length, dtype=torch.long)\n",
        "  for i, tokens in enumerate(text_tokens):\n",
        "    text_input[i, :len(tokens)] = torch.tensor(tokens)\n",
        "  text_input = text_input.cuda()\n",
        "  with torch.no_grad():\n",
        "    text_features = model.encode_text(text_input).float()\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "  return text_features\n",
        "def get_top_N_semantic_similarity(similarity_list, N):\n",
        "  results = zip(range(len(similarity_list)), similarity_list)\n",
        "  results = sorted(results, key=lambda x: x[1],reverse= True)\n",
        "  top_N_images = []\n",
        "  scores = []\n",
        "  indices = []\n",
        "  for index,score in results[:N]:\n",
        "    scores.append(score)\n",
        "    image = Image.open(image_files[index])\n",
        "    top_N_images.append(image)\n",
        "    # top_N_images.append(all_images[index])\n",
        "    indices.append(index)\n",
        "  return scores, top_N_images, indices\n",
        "  import ipyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tj0DJEDrC5d",
        "cellView": "form"
      },
      "source": [
        "query = \"chaise lounge\" #@param {type:\"string\"}\r\n",
        "query_type = \"text search\" #@param [\"text search\", \"image search\", \"combined search\"]\r\n",
        "num_results = 7 #@param {type:\"slider\", min:1, max:14, step:1}\r\n",
        "text_features_extracted = get_text_features(query)\r\n",
        "if query_type == \"text search\":\r\n",
        "  similarity = text_features_extracted.cpu().numpy() @ text_features.numpy().T\r\n",
        "elif query_type == \"image search\":\r\n",
        "  similarity = text_features_extracted.cpu().numpy() @ image_features.numpy().T\r\n",
        "else:\r\n",
        "  double_features_extracted = torch.hstack((text_features_extracted, text_features_extracted))\r\n",
        "  similarity = double_features_extracted.cpu().numpy() @ combined_features.numpy().T\r\n",
        "similarity = similarity[0]\r\n",
        "scores, imgs, indices = get_top_N_semantic_similarity(similarity, N=num_results)\r\n",
        "# print(query_type, \"results\", scores)\r\n",
        "result_labels = []\r\n",
        "for i in indices:\r\n",
        "  file_name = image_files[i]\r\n",
        "  parts = file_name.split(\"/\")\r\n",
        "  patent_name = parts[1][:-4]\r\n",
        "  label = labels[patent_name]\r\n",
        "  result_labels.append(label + \" \" + patent_name)\r\n",
        "ipyplot.plot_images(imgs, img_width=224, labels=result_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
